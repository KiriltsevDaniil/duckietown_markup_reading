{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIDO_MobileNet_traincamp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pIpCHw0lm3I"
      },
      "source": [
        "#импортируем нужные библиотеки\n",
        "import os\n",
        "import pandas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import PIL.Image as Image"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlk_gPPgl89w"
      },
      "source": [
        " #Объявляем путь, где хранятся датасет и csv файл\n",
        "drive.mount(\"/MyDrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9pwnnrQmAwc"
      },
      "source": [
        "#Определяем пути более точно + гиперпараметры\n",
        "num_epochs = 6 \n",
        "num_classes = 6 \n",
        "batch_size = 25 \n",
        "learning_rate = 0.0001\n",
        "dataset_path = '/MyDrive/MyDrive/cropped_dataset/dataset'\n",
        "model_store_path = '/MyDrive/MyDrive'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajbIQYRHmDnE"
      },
      "source": [
        "#функция для перевода текстовых классов в цифровые метки\n",
        "def target_conv(line):\n",
        "    targets = [\"no-left-turn-1\", \"T-intersection-1\", \"right-T-intersection-1\", \"left-T-intersection-1\", \"stop-1\", \"traffic-light-1\"]\n",
        "    i = 0\n",
        "    for target in targets:\n",
        "        if target == line:\n",
        "            return i\n",
        "        else:\n",
        "            i+=1\n",
        "    return 6"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Um-Yc2omHcP"
      },
      "source": [
        "#инициализация класса для подачи датасета в сеть\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pandas.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1]) #change to PIL\n",
        "        image = Image.open(img_path)\n",
        "        y_label = torch.tensor(int(target_conv(self.annotations.iloc[index, 4]))) \n",
        "\n",
        "        if self.transform:\n",
        "            tr = nn.AdaptiveMaxPool2d(157) \n",
        "            image = self.transform(image)\n",
        "            image = tr(image)\n",
        "          \n",
        "        return (image, y_label)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjInn9ljmPPM"
      },
      "source": [
        "#Приведение к тензорам, нормализация и распределение изображений датасета\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
        "\n",
        "dataset = MyDataset(csv_file=\"/MyDrive/MyDrive/cropped_dataset/markup.csv\", root_dir=dataset_path, transform=transforms.ToTensor())\n",
        "trainset, testset = torch.utils.data.random_split(dataset, [319,319])\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C64OKI8SmTJ0"
      },
      "source": [
        "#Загрузка модели\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(1280, 6)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqaX8MnQmWce"
      },
      "source": [
        "#Обучение\n",
        "total_step = len(trainloader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(trainloader):\n",
        "        # Прямой запуск\n",
        "        print(images.shape)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # точность\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a1RgwnSmeOc",
        "outputId": "c7600353-acff-4479-a7a2-db71972fd4f9"
      },
      "source": [
        "#Тест\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 318 test images: {} %'.format((correct / total) * 100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 318 test images: 95.61128526645768 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}